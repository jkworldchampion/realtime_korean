import tempfile
import streamlit as st
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.llms import Ollama
from langchain.document_loaders import PyPDFLoader

# ì¶”ê°€í•˜ëŠ” library
import streamlit.components.v1 as components

# Ollama ì–¸ì–´ ëª¨ë¸ ì„œë²„ì˜ ê¸°ë³¸ URL
CUSTOM_URL = "http://localhost:11434"


# ìš”ì•½ì„ ìœ„í•œ Ollama ì–¸ì–´ ëª¨ë¸ ì´ˆê¸°í™”
llm = Ollama(
    model="llama3.1:8b", 
    base_url=CUSTOM_URL, 
    temperature=0,
    num_predict=200
)

# ë²ˆì—­ì„ ìœ„í•œ í•¨ìˆ˜
def translate_text(text):
    map_prompt_template = """
    - you are a professional translator
    - translate the provided content into Korean
    - only respond with the translation
    {text}
    """
    prompt_text = map_prompt_template.format(text=text)
    stream_generator = llm.stream(prompt_text)
    
    translation_result = ""
    for chunk in stream_generator:
        translation_result += chunk
    return translation_result

# Streamlit ì•±ì˜ ì œëª© êµ¬ì„±
st.title(" ğŸ¦œì•µë¬´ SayğŸ¦œ")

def main():
    """
    Streamlit ì•±ì„ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜.
    """
    if 'translation_result' not in st.session_state:
        st.session_state.translation_result = ""

    # ì—¬ê¸°ì„œë¶€í„° ë‚´ê°€ ë¹Œë“œí•œë‹¤.
    col1, col2 = st.columns(2)
    col1.write("ì¸ì‹")
    user_input = st.text_input("ì‚¬ìš©ì ìŒì„± ì…ë ¥:")

    col2.write("ë²ˆì—­")

    html_code = """
        <!DOCTYPE html>
            <html lang="en">
            <head>
                <meta charset="UTF-8">
                <meta name="viewport" content="width=device-width, initial-scale=1.0">
                <title>ìŒì„± ì¸ì‹</title>
            </head>
            <body>
                <button id="start-btn">ìŒì„± ì¸ì‹ ì‹œì‘</button>
                <button id="stop-btn">ìŒì„± ì¸ì‹ ì¤‘ì§€</button>
                <p id="transcript">ìŒì„± ì¸ì‹ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤: <br></p>
                <p id="translated">ë²ˆì—­ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤: <br></p>

                <script>
                    const startBtn = document.getElementById('start-btn');
                    const stopBtn = document.getElementById('stop-btn');
                    const transcriptElement = document.getElementById('transcript');
                    const translatedElement = document.getElementById('translated');
                    
                    // ìŒì„± -> í…ìŠ¤íŠ¸
                    let recognition;  // 
                    let translation = '';  // ë²ˆì—­ëœ ê²°ê³¼ë¥¼ ì €ì¥í•  ë³€ìˆ˜
                    let lastTranscript = '';  // ë§ˆì§€ë§‰ìœ¼ë¡œ ì²˜ë¦¬ëœ transcriptë¥¼ ì €ì¥

                    if (!('webkitSpeechRecognition' in window)) {  // ì›¹ì‚¬ì´íŠ¸ê°€ ë§í•˜ê¸° ì¸ì‹ì´ ë˜ëŠ”ì§€ í™•ì¸
                        transcriptElement.innerText = "ì´ browseì—ì„œëŠ” Web Speech APIê°€ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤...";  // ì•ˆë˜ë©´ error ë‚´ë±‰ê¸°
                    } else {
                        recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
                        recognition.lang = 'en-us';  // ì–¸ì–´ ì„¤ì •
                        recognition.interimResults = false;  // ì¤‘ê°„ì— ëŠì„ ê²ƒì¸ì§€, ì´ì–´ì„œ ë°›ì„ ê²ƒì¸ì§€
                        recognition.continuous = true;

                        // ìŒì„±ì¸ì‹ ê²°ê³¼ê°€ ì¶œë ¥ë˜ëŠ” ë¶€ë¶„
                        recognition.onresult = function(event) {
                            let currentTranscript = transcriptElement.innerText;  // ê¸°ì¡´ í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜´
                            let newTranscript = '';  // ìƒˆë¡œ ì¸ì‹ëœ í…ìŠ¤íŠ¸ë¥¼ ì €ì¥í•  ë³€ìˆ˜

                            for (let i = event.resultIndex; i < event.results.length; i++) {
                                newTranscript += event.results[i][0].transcript;
                            }

                            // ê¸°ì¡´ í…ìŠ¤íŠ¸ì— ìƒˆë¡œ ì¸ì‹ëœ ë‚´ìš©ì„ ì¶”ê°€í•˜ì—¬ í™”ë©´ì— í‘œì‹œ!!!!! ì—¬ê¸°ì„œ ì¶œë ¥í•¨.
                            transcriptElement.innerText = currentTranscript + newTranscript;

                            // ì„œë²„ë¡œ ëˆ„ì ëœ ê²°ê³¼ë¥¼ ì „ì†¡
                            fetch('/update_transcript', {
                                method: 'POST',
                                headers: {
                                    'Content-Type': 'application/json',
                                },
                                body: JSON.stringify({ text: transcriptElement.innerText }),  // ëˆ„ì ëœ í…ìŠ¤íŠ¸ ì „ì²´ë¥¼ ì„œë²„ì— ë³´ëƒ„
                            })
                            .then(response => response.json())  // ì„œë²„ì—ì„œ ì‘ë‹µì´ JSON í˜•íƒœë¡œ ì˜¬ ë•Œ
                            .then(data => {
                                // ì„œë²„ì—ì„œ ì²˜ë¦¬í•œ ê²°ê³¼ë¥¼ ë°›ì•„ì„œ í™”ë©´ì— í‘œì‹œ (ì˜µì…˜ ì‚¬í•­)
                                // transcriptElement.innerText = data.processedText;
                            });
                        };

                        recognition.onerror = function(event) {
                            console.error('Speech recognition error:', event.error);
                        };

                        recognition.onend = function() {
                            console.log('Speech recognition ended');
                        };

                        startBtn.addEventListener('click', function() {
                            if (recognition) {
                                recognition.start();
                            }
                        });

                        stopBtn.addEventListener('click', function() {
                            if (recognition) {
                                recognition.stop();
                            }
                        });
                    }
                </script>
            </body>
        </html>
    """
    components.html(html_code, height=400)


if __name__ == "__main__":
    main()